\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\select@language{american}
\@writefile{toc}{\select@language{american}}
\@writefile{lof}{\select@language{american}}
\@writefile{lot}{\select@language{american}}
\citation{who}
\citation{deaths}
\citation{bruffaerts2011treatment,ryan2010universal,crosby2011self}
\citation{mann1999toward}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}}
\citation{crosby2011self,horowitz2009suicide}
\citation{crosby2011self}
\citation{nock2008suicide}
\citation{stone}
\citation{pestinaetal2008,Pestian2}
\citation{kincaid1975derivation}
\citation{gayo2013meta}
\citation{bollen2011twitter}
\citation{lampocris}
\citation{golbeck2011predicting}
\citation{song2010limits}
\citation{asur2010predicting}
\citation{Pang}
\citation{Turney}
\citation{Pang}
\citation{Snyder07multipleaspect}
\citation{read2005using}
\citation{Go}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{4}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Related Work}{4}{section.3}}
\citation{pennebaker2001linguistic}
\citation{Baccianella}
\citation{ChoudhuryGCH13}
\citation{ponePrieto}
\citation{ChoudhuryGCH13}
\citation{ponePrieto}
\citation{Jay}
\@writefile{toc}{\contentsline {section}{\numberline {4}NLP Techniques}{5}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Text Normalization}{5}{subsection.4.1}}
\citation{Blei}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Bag of Words}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}\emph  {n}-gram Modeling}{6}{subsubsection.4.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Term Frequency-Inverse Document Frequency}{6}{subsection.4.3}}
\newlabel{eq:tf}{{1}{6}{Term Frequency-Inverse Document Frequency\relax }{equation.4.1}{}}
\newlabel{eq:idf}{{2}{6}{Term Frequency-Inverse Document Frequency\relax }{equation.4.2}{}}
\newlabel{eq:tfidf}{{3}{6}{Term Frequency-Inverse Document Frequency\relax }{equation.4.3}{}}
\citation{cortes}
\citation{Aizerman67theoretical}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Latent Dirichlet Allocation}{7}{subsection.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example input for annotator. \relax }}{7}{figure.caption.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Support Vector Machine}{7}{subsection.4.5}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Dataset}{7}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Human Subject Research}{7}{subsection.5.1}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Current Work}{8}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Annotation}{8}{subsection.6.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example input for annotator. The text within "$>>>$" and "$<<<$" is the current tweet\relax }}{8}{figure.caption.6}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:example}{{2}{8}{Example input for annotator. The text within "$>>>$" and "$<<<$" is the current tweet\relax \relax }{figure.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Distress-related categories used to annotate the tweets.\relax }}{8}{table.caption.7}}
\newlabel{tab:distress}{{1}{8}{Distress-related categories used to annotate the tweets.\relax \relax }{table.caption.7}{}}
\newlabel{fig:gull}{{3a}{9}{Using tweets annotated by Novices 1 and 2 (N=250, identical set).\relax \relax }{figure.caption.8}{}}
\newlabel{sub@fig:gull}{{a}{9}{Using tweets annotated by Novices 1 and 2 (N=250, identical set).\relax \relax }{figure.caption.8}{}}
\newlabel{fig:tiger}{{3b}{9}{Using tweets annotated by Novice 1 and Expert. Note the these two datasets are disjoint (N = 1000 tweets, respectively)\relax \relax }{figure.caption.8}{}}
\newlabel{sub@fig:tiger}{{b}{9}{Using tweets annotated by Novice 1 and Expert. Note the these two datasets are disjoint (N = 1000 tweets, respectively)\relax \relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Distribution of distress level annotations\relax }}{9}{figure.caption.8}}
\newlabel{fig:distributions}{{3}{9}{Distribution of distress level annotations\relax \relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Modeling and Results}{9}{subsection.6.2}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Topic analysis on bigrams of tweets labeled as high distress vs.\ randomly selected tweets from the larger, unlabeled dataset. The high distress tweets clearly convey strong negative affect.\relax }}{9}{table.caption.9}}
\newlabel{tab:tm}{{2}{9}{Topic analysis on bigrams of tweets labeled as high distress vs.\ randomly selected tweets from the larger, unlabeled dataset. The high distress tweets clearly convey strong negative affect.\relax \relax }{table.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance of SVM-based classification when the training and testing sets are alternately Novice 1 (N1) or the Expert (E). Because we focus on distress classification, we report precision, recall and F-measure for the distress class, which combines LD and HD into a single class with respect to binary (distress vs.\ non-distress) classification. In each case, a held-out set of 100 randomly selected tweets compose the test set and the remaining 900 tweets from that annotator compose the training set. The last row shows when the two training sets (respectively, test sets) are combined into a single set of 1800 (respectively, 200) tweets. \relax }}{10}{table.caption.10}}
\newlabel{tab:svm}{{3}{10}{Performance of SVM-based classification when the training and testing sets are alternately Novice 1 (N1) or the Expert (E). Because we focus on distress classification, we report precision, recall and F-measure for the distress class, which combines LD and HD into a single class with respect to binary (distress vs.\ non-distress) classification. In each case, a held-out set of 100 randomly selected tweets compose the test set and the remaining 900 tweets from that annotator compose the training set. The last row shows when the two training sets (respectively, test sets) are combined into a single set of 1800 (respectively, 200) tweets. \relax \relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Solution Design and Implementation}{10}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Visulizations}{10}{subsection.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Social Network}{10}{subsection.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Modeling for Reddit Data}{10}{subsection.7.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Outcome}{10}{subsection.7.4}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Roadmap}{10}{section.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Deliverables}{10}{subsection.8.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Timeline}{10}{subsection.8.2}}
\bibstyle{apalike}
\bibdata{Proposal}
\bibcite{Aizerman67theoretical}{{1}{1964}{{Aizerman et~al.}}{{}}}
\bibcite{asur2010predicting}{{2}{2010}{{Asur and Huberman}}{{}}}
\bibcite{Baccianella}{{3}{2010}{{Baccianella et~al.}}{{}}}
\bibcite{Blei}{{4}{2003}{{Blei et~al.}}{{}}}
\bibcite{bollen2011twitter}{{5}{2011}{{Bollen et~al.}}{{}}}
\bibcite{bruffaerts2011treatment}{{6}{2011}{{Bruffaerts et~al.}}{{}}}
\bibcite{ChoudhuryGCH13}{{7}{2013}{{Choudhury et~al.}}{{}}}
\bibcite{cortes}{{8}{1995}{{Cortes and Vapnik}}{{}}}
\bibcite{crosby2011self}{{9}{2011}{{Crosby et~al.}}{{}}}
\bibcite{gayo2013meta}{{10}{2013}{{Gayo-Avello}}{{}}}
\bibcite{Go}{{11}{2009}{{Go et~al.}}{{}}}
\bibcite{golbeck2011predicting}{{12}{2011}{{Golbeck et~al.}}{{}}}
\bibcite{horowitz2009suicide}{{13}{2009}{{Horowitz and Ballard}}{{}}}
\bibcite{Jay}{{14}{2013}{{Jashinsky et~al.}}{{}}}
\bibcite{kincaid1975derivation}{{15}{1975}{{Kincaid et~al.}}{{}}}
\bibcite{deaths}{{16}{2008}{{Kung et~al.}}{{}}}
\bibcite{lampocris}{{17}{2010}{{Lampos and Cristianini}}{{}}}
\bibcite{mann1999toward}{{18}{1999}{{Mann et~al.}}{{}}}
\bibcite{nock2008suicide}{{19}{2008}{{Nock et~al.}}{{}}}
\bibcite{Pang}{{20}{2002}{{Pang et~al.}}{{}}}
\bibcite{pennebaker2001linguistic}{{21}{2001}{{Pennebaker et~al.}}{{}}}
\bibcite{Pestian2}{{22}{2010}{{Pestian et~al.}}{{}}}
\bibcite{pestinaetal2008}{{23}{2008}{{Pestian et~al.}}{{}}}
\bibcite{ponePrieto}{{24}{2014}{{Prieto et~al.}}{{}}}
\bibcite{read2005using}{{25}{2005}{{Read}}{{}}}
\bibcite{ryan2010universal}{{26}{2010}{{Ryan et~al.}}{{}}}
\bibcite{Snyder07multipleaspect}{{27}{2007}{{Snyder and Barzilay}}{{}}}
\bibcite{song2010limits}{{28}{2010}{{Song et~al.}}{{}}}
\bibcite{stone}{{29}{1963}{{Stone and Hunt}}{{}}}
\bibcite{Turney}{{30}{2002}{{Turney}}{{}}}
\bibcite{who}{{31}{2002}{{World Health Organisation}}{{}}}
